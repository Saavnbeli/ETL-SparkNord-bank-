{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building environment  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing necessary modules/lib\n",
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/opt/cloudera/parcels/Anaconda/bin/python\"\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/java/jdk1.8.0_161/jre\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/cloudera/parcels/SPARK2-2.3.0.cloudera2-1.cdh5.13.3.p0.316101/lib/spark2/\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.6-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, BooleanType, DoubleType, LongType, FloatType\n",
    "from pyspark.sql.functions import col,lit\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.functions import from_unixtime\n",
    "from pyspark.sql.functions import unix_timestamp\n",
    "from pyspark.sql.functions import concat\n",
    "from pyspark.sql.functions import lpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-10-0-0-201.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0.cloudera2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ETL</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff3f4663610>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Starting/checking session with app name \"elt_project\"\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('ETL').master(\"local\").getOrCreate()\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading dataframe from hdfs\n",
    "# naming dataframe as df\n",
    "df = spark.read.csv(\"/user/root/etl_atm_project/part-m-00000\", inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+---+------+---+------+---+---+----------+-----------+----+----+------+------+----+----------+----+----------+----+----+-----+------+-------+--------+------+----+----+----+----+-----+----+----+----+----------+\n",
      "| _c0|    _c1|_c2|   _c3|_c4|   _c5|_c6|_c7|       _c8|        _c9|_c10|_c11|  _c12|  _c13|_c14|      _c15|_c16|      _c17|_c18|_c19| _c20|  _c21|   _c22|    _c23|  _c24|_c25|_c26|_c27|_c28| _c29|_c30|_c31|_c32|      _c33|\n",
      "+----+-------+---+------+---+------+---+---+----------+-----------+----+----+------+------+----+----------+----+----------+----+----+-----+------+-------+--------+------+----+----+----+----+-----+----+----+----+----------+\n",
      "|2017|January|  1|Sunday|  0|Active|  1|NCR|NÃƒÂ¦stved|Farimagsvej|   8|4700|55.233|11.763| DKK|MasterCard|5643|Withdrawal|null|null|55.23|11.761|2616038|Naestved|281.15|1014|  87|   7| 260|0.215|  92| 500|Rain|light rain|\n",
      "+----+-------+---+------+---+------+---+---+----------+-----------+----+----+------+------+----+----------+----+----------+----+----+-----+------+-------+--------+------+----+----+----+----+-----+----+----+----+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking first row \n",
    "df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferences \n",
    "- As seen above no headers for columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: integer (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: integer (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: integer (nullable = true)\n",
      " |-- _c11: integer (nullable = true)\n",
      " |-- _c12: double (nullable = true)\n",
      " |-- _c13: double (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: integer (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: integer (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      " |-- _c20: double (nullable = true)\n",
      " |-- _c21: double (nullable = true)\n",
      " |-- _c22: integer (nullable = true)\n",
      " |-- _c23: string (nullable = true)\n",
      " |-- _c24: double (nullable = true)\n",
      " |-- _c25: integer (nullable = true)\n",
      " |-- _c26: integer (nullable = true)\n",
      " |-- _c27: integer (nullable = true)\n",
      " |-- _c28: integer (nullable = true)\n",
      " |-- _c29: double (nullable = true)\n",
      " |-- _c30: integer (nullable = true)\n",
      " |-- _c31: integer (nullable = true)\n",
      " |-- _c32: string (nullable = true)\n",
      " |-- _c33: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking count thus vaildating from the document provided  \n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new schema as 'dfschema' with respective structypes and naming the coloumns as well\n",
    "dfschema = StructType([StructField('year', IntegerType(),True),\n",
    "                                    StructField('month', StringType(),True),\n",
    "                                    StructField('day', IntegerType(),True),\n",
    "                                    StructField('weekday', StringType(),True),\n",
    "                                    StructField('hour', IntegerType(),True),\n",
    "                                    StructField('atm_status', StringType(),True),\n",
    "                                    StructField('atm_id', StringType(),True),\n",
    "                                    StructField('atm_manufacturer', StringType(),True),\n",
    "                                    StructField('atm_location', StringType(),True),\n",
    "                                    StructField('atm_streetname', StringType(),True),\n",
    "                                    StructField('atm_street_number', IntegerType(),True),\n",
    "                                    StructField('atm_zipcode', IntegerType(),True),\n",
    "                                    StructField('atm_lat', FloatType(),True),\n",
    "                                    StructField('atm_lon', FloatType(),True),\n",
    "                                    StructField('currency', StringType(),True),\n",
    "                                    StructField('card_type', StringType(),True),\n",
    "                                    StructField('transaction_amount', IntegerType(),True),\n",
    "                                    StructField('service', StringType(),True),\n",
    "                                    StructField('message_code', StringType(),True),\n",
    "                                    StructField('message_text', StringType(),True),\n",
    "                                    StructField('weather_lat', FloatType(),True),\n",
    "                                    StructField('weather_lon', FloatType(),True),\n",
    "                                    StructField('weather_city_id', IntegerType(),True),\n",
    "                                    StructField('weather_city_name', StringType(),True),\n",
    "                                    StructField('temp', FloatType(),True),\n",
    "                                    StructField('pressure', IntegerType(),True),\n",
    "                                    StructField('humidity', IntegerType(),True),\n",
    "                                    StructField('wind_speed', IntegerType(),True),\n",
    "                                    StructField('wind_deg', IntegerType(),True),\n",
    "                                    StructField('rain_3h', FloatType(),True),\n",
    "                                    StructField('clouds_all', IntegerType(),True),\n",
    "                                    StructField('weather_id', IntegerType(),True),\n",
    "                                    StructField('weather_main', StringType(),True),\n",
    "                                    StructField('weather_description', StringType(),True),])\n",
    "\n",
    "                                    \n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the file with dfschema\n",
    "input_df = spark.read.csv(\"/user/root/etl_atm_project/part-m-00000\", schema = dfschema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+---+-------+----+----------+------+----------------+------------+-------------------+-----------------+-----------+-------+-------+--------+----------+------------------+----------+------------+------------+-----------+-----------+---------------+-----------------+------+--------+--------+----------+--------+-------+----------+----------+------------+--------------------+\n",
      "|year|  month|day|weekday|hour|atm_status|atm_id|atm_manufacturer|atm_location|     atm_streetname|atm_street_number|atm_zipcode|atm_lat|atm_lon|currency| card_type|transaction_amount|   service|message_code|message_text|weather_lat|weather_lon|weather_city_id|weather_city_name|  temp|pressure|humidity|wind_speed|wind_deg|rain_3h|clouds_all|weather_id|weather_main| weather_description|\n",
      "+----+-------+---+-------+----+----------+------+----------------+------------+-------------------+-----------------+-----------+-------+-------+--------+----------+------------------+----------+------------+------------+-----------+-----------+---------------+-----------------+------+--------+--------+----------+--------+-------+----------+----------+------------+--------------------+\n",
      "|2017|January|  1| Sunday|   0|    Active|     1|             NCR|  NÃƒÂ¦stved|        Farimagsvej|                8|       4700| 55.233| 11.763|     DKK|MasterCard|              5643|Withdrawal|        null|        null|      55.23|     11.761|        2616038|         Naestved|281.15|    1014|      87|         7|     260|  0.215|        92|       500|        Rain|          light rain|\n",
      "|2017|January|  1| Sunday|   0|  Inactive|     2|             NCR|    Vejgaard|         Hadsundvej|               20|       9000| 57.043|   9.95|     DKK|MasterCard|              1764|Withdrawal|        null|        null|     57.048|      9.935|        2616235|   NÃƒÂ¸rresundby|280.64|    1020|      93|         9|     250|   0.59|        92|       500|        Rain|          light rain|\n",
      "|2017|January|  1| Sunday|   0|  Inactive|     2|             NCR|    Vejgaard|         Hadsundvej|               20|       9000| 57.043|   9.95|     DKK|      VISA|              1891|Withdrawal|        null|        null|     57.048|      9.935|        2616235|   NÃƒÂ¸rresundby|280.64|    1020|      93|         9|     250|   0.59|        92|       500|        Rain|          light rain|\n",
      "|2017|January|  1| Sunday|   0|  Inactive|     3|             NCR|       Ikast|RÃƒÂ¥dhusstrÃƒÂ¦det|               12|       7430| 56.139|  9.154|     DKK|      VISA|              4166|Withdrawal|        null|        null|     56.139|      9.158|        2619426|            Ikast|281.15|    1011|     100|         6|     240|    0.0|        75|       300|     Drizzle|light intensity d...|\n",
      "|2017|January|  1| Sunday|   0|    Active|     4|             NCR|  Svogerslev|       BrÃƒÂ¸nsager|                1|       4000| 55.634| 12.018|     DKK|MasterCard|              5153|Withdrawal|        null|        null|     55.642|      12.08|        2614481|         Roskilde|280.61|    1014|      87|         7|     260|    0.0|        88|       701|        Mist|                mist|\n",
      "+----+-------+---+-------+----+----------+------+----------------+------------+-------------------+-----------------+-----------+-------+-------+--------+----------+------------------+----------+------------+------------+-----------+-----------+---------------+-----------------+------+--------+--------+----------+--------+-------+----------+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking top 5 rows\n",
    "input_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'weekday',\n",
       " 'hour',\n",
       " 'atm_status',\n",
       " 'atm_id',\n",
       " 'atm_manufacturer',\n",
       " 'atm_location',\n",
       " 'atm_streetname',\n",
       " 'atm_street_number',\n",
       " 'atm_zipcode',\n",
       " 'atm_lat',\n",
       " 'atm_lon',\n",
       " 'currency',\n",
       " 'card_type',\n",
       " 'transaction_amount',\n",
       " 'service',\n",
       " 'message_code',\n",
       " 'message_text',\n",
       " 'weather_lat',\n",
       " 'weather_lon',\n",
       " 'weather_city_id',\n",
       " 'weather_city_name',\n",
       " 'temp',\n",
       " 'pressure',\n",
       " 'humidity',\n",
       " 'wind_speed',\n",
       " 'wind_deg',\n",
       " 'rain_3h',\n",
       " 'clouds_all',\n",
       " 'weather_id',\n",
       " 'weather_main',\n",
       " 'weather_description']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking list of columns\n",
    "input_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- atm_id: string (nullable = true)\n",
      " |-- atm_manufacturer: string (nullable = true)\n",
      " |-- atm_location: string (nullable = true)\n",
      " |-- atm_streetname: string (nullable = true)\n",
      " |-- atm_street_number: integer (nullable = true)\n",
      " |-- atm_zipcode: integer (nullable = true)\n",
      " |-- atm_lat: float (nullable = true)\n",
      " |-- atm_lon: float (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- weather_lat: float (nullable = true)\n",
      " |-- weather_lon: float (nullable = true)\n",
      " |-- weather_city_id: integer (nullable = true)\n",
      " |-- weather_city_name: string (nullable = true)\n",
      " |-- temp: float (nullable = true)\n",
      " |-- pressure: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_deg: integer (nullable = true)\n",
      " |-- rain_3h: float (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rechecking schema\n",
    "input_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8087"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking for null values in weather_main\n",
    "input_df.filter(input_df.weather_main.isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# craeting a function to check null values in dataframe \n",
    "import pyspark.sql.functions as F\n",
    "def count_missings(spark_df,sort=True):\n",
    "    \"\"\"\n",
    "    Counts number of nulls and nans in each column\n",
    "    \"\"\"\n",
    "    df = spark_df.select([F.count(F.when(F.isnan(c) | F.isnull(c), c)).alias(c) for (c,c_type) in spark_df.dtypes if c_type not in ('timestamp', 'date')]).toPandas()\n",
    "\n",
    "    if len(df) == 0:\n",
    "        print(\"There are no any missing values!\")\n",
    "        return None\n",
    "\n",
    "    if sort:\n",
    "        return df.rename(index={0: 'count'}).T.sort_values(\"count\",ascending=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>message_text</th>\n",
       "      <td>2459010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message_code</th>\n",
       "      <td>2459009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pressure</th>\n",
       "      <td>8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_lat</th>\n",
       "      <td>8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_lon</th>\n",
       "      <td>8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_city_id</th>\n",
       "      <td>8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_city_name</th>\n",
       "      <td>8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_description</th>\n",
       "      <td>8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind_speed</th>\n",
       "      <td>8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind_deg</th>\n",
       "      <td>8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rain_3h</th>\n",
       "      <td>8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clouds_all</th>\n",
       "      <td>8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_id</th>\n",
       "      <td>8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_main</th>\n",
       "      <td>8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity</th>\n",
       "      <td>8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_amount</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card_type</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atm_lon</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atm_lat</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atm_zipcode</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atm_street_number</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atm_streetname</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atm_location</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atm_manufacturer</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atm_id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atm_status</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count\n",
       "message_text         2459010\n",
       "message_code         2459009\n",
       "pressure                8087\n",
       "weather_lat             8087\n",
       "weather_lon             8087\n",
       "weather_city_id         8087\n",
       "weather_city_name       8087\n",
       "temp                    8087\n",
       "weather_description     8087\n",
       "wind_speed              8087\n",
       "wind_deg                8087\n",
       "rain_3h                 8087\n",
       "clouds_all              8087\n",
       "weather_id              8087\n",
       "weather_main            8087\n",
       "humidity                8087\n",
       "month                      0\n",
       "year                       0\n",
       "transaction_amount         0\n",
       "card_type                  0\n",
       "currency                   0\n",
       "atm_lon                    0\n",
       "atm_lat                    0\n",
       "atm_zipcode                0\n",
       "atm_street_number          0\n",
       "atm_streetname             0\n",
       "atm_location               0\n",
       "atm_manufacturer           0\n",
       "atm_id                     0\n",
       "atm_status                 0\n",
       "hour                       0\n",
       "weekday                    0\n",
       "day                        0\n",
       "service                    0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking null values \n",
    "count_missings(input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferences \n",
    "- As seen above few columns contains null values but data dict says only message columns will have null values depicting no error was there but apart from that i suppose thats data quality issue beacsue same problem is faced by everyone "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dimension tables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating location dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading respective columns for location dimension from input_df\n",
    "\n",
    "dim_location = input_df.select([input_df.atm_location.alias(\"location\"),input_df.atm_streetname.alias(\"streetname\"),input_df.atm_street_number.alias(\"street_number\"),input_df.atm_zipcode.alias(\"zipcode\"),input_df.atm_lat.alias(\"lat\"),input_df.atm_lon.alias(\"lon\")]).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-------------+-------+------+-----+\n",
      "|            location| streetname|street_number|zipcode|   lat|  lon|\n",
      "+--------------------+-----------+-------------+-------+------+-----+\n",
      "|Aalborg Storcente...|   Hobrovej|          452|   9200|57.005|9.876|\n",
      "|            Hasseris|Hasserisvej|          113|   9000|57.044|9.898|\n",
      "+--------------------+-----------+-------------+-------+------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking top two rows \n",
    "\n",
    "dim_location.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking count of location table\n",
    "dim_location.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+-----------+-------------+-------+------+------+\n",
      "|location                  |streetname |street_number|zipcode|lat   |lon   |\n",
      "+--------------------------+-----------+-------------+-------+------+------+\n",
      "|Aalborg Storcenter indg. D|Hobrovej   |452          |9200   |57.005|9.876 |\n",
      "|Hasseris                  |Hasserisvej|113          |9000   |57.044|9.898 |\n",
      "|Bispensgade               |Bispensgade|35           |9800   |57.453|9.996 |\n",
      "|HolbÃƒÂ¦k                 |Slotsvolden|7            |4300   |55.718|11.704|\n",
      "|Bindslev                  |NÃƒÂ¸rrebro|18           |9881   |57.541|10.2  |\n",
      "+--------------------------+-----------+-------------+-------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking top 5 rows\n",
    "dim_location.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- location: string (nullable = true)\n",
      " |-- streetname: string (nullable = true)\n",
      " |-- street_number: integer (nullable = true)\n",
      " |-- zipcode: integer (nullable = true)\n",
      " |-- lat: float (nullable = true)\n",
      " |-- lon: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking schema\n",
    "dim_location.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adding column for primary key\n",
    "dim_location= dim_location.withColumn(\"new_column\",lit(\"ABC\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating primary key \n",
    "w = Window().partitionBy('new_column').orderBy(lit('A'))\n",
    "dim_location= dim_location.withColumn(\"atm_location_id\", row_number().over(w)).drop(\"new_column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- location: string (nullable = true)\n",
      " |-- streetname: string (nullable = true)\n",
      " |-- street_number: integer (nullable = true)\n",
      " |-- zipcode: integer (nullable = true)\n",
      " |-- lat: float (nullable = true)\n",
      " |-- lon: float (nullable = true)\n",
      " |-- atm_location_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking schema\n",
    "dim_location.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-------------+-------+------+-----+---------------+\n",
      "|            location| streetname|street_number|zipcode|   lat|  lon|atm_location_id|\n",
      "+--------------------+-----------+-------------+-------+------+-----+---------------+\n",
      "|Aalborg Storcente...|   Hobrovej|          452|   9200|57.005|9.876|              1|\n",
      "|            Hasseris|Hasserisvej|          113|   9000|57.044|9.898|              2|\n",
      "+--------------------+-----------+-------------+-------+------+-----+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking rows \n",
    "dim_location.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking count\n",
    "dim_location.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(location=u'Hj\\xc3\\u0192\\xc2\\xb8rring', streetname=u'\\xc3\\u0192\\xcb\\u0153stergade', street_number=8, zipcode=9800, lat=57.45899963378906, lon=9.98799991607666, atm_location_id=107),\n",
       " Row(location=u'Vodskov', streetname=u'Vodskovvej', street_number=27, zipcode=9310, lat=57.104000091552734, lon=10.027000427246094, atm_location_id=108),\n",
       " Row(location=u'Vadum', streetname=u'Ellehammersvej', street_number=43, zipcode=9430, lat=57.11800003051758, lon=9.861000061035156, atm_location_id=109)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_location.filter(dim_location['atm_location_id'] > 106).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange dim_location\n",
    "location = dim_location.select(\"atm_location_id\",\"location\",\"streetname\",\"street_number\",\"zipcode\",\"lat\",\"lon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Finding the count for validation hence verified \n",
    "location.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating card_type dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating card_type dimension\n",
    "dim_card_type = input_df.select([input_df.card_type.alias(\"card_type\")]).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #checking count for validation hence verified\n",
    "dim_card_type.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating primary key or card_type_id column\n",
    "dim_card_type= dim_card_type.withColumn(\"new_column\",lit(\"ABC\"))\n",
    "w = Window().partitionBy('new_column').orderBy(lit('A'))\n",
    "dim_card_type= dim_card_type.withColumn(\"card_type_id\", row_number().over(w)).drop(\"new_column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+\n",
      "|         card_type|card_type_id|\n",
      "+------------------+------------+\n",
      "|   Dankort - on-us|           1|\n",
      "|            CIRRUS|           2|\n",
      "|       HÃƒÂ¦vekort|           3|\n",
      "|              VISA|           4|\n",
      "|Mastercard - on-us|           5|\n",
      "+------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Checking dataframe's top 5 rows\n",
    "dim_card_type.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dim_card_type as card_type\n",
    "card_type = dim_card_type.select(\"card_type_id\",\"card_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the count for validation\n",
    "card_type.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- card_type_id: integer (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking schema\n",
    "card_type.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Craeting date dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating date data fame\n",
    "dim_date = input_df.select([input_df.year.alias(\"year\"),input_df.month.alias(\"month\"),input_df.day.alias(\"day\"),input_df.hour.alias(\"hour\"),input_df.weekday.alias(\"weekday\")]).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8685"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the count for validation hence verified\n",
    "\n",
    "dim_date.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---+----+--------+\n",
      "|year|   month|day|hour| weekday|\n",
      "+----+--------+---+----+--------+\n",
      "|2017| January|  1|   9|  Sunday|\n",
      "|2017| January|  3|   5| Tuesday|\n",
      "|2017| January|  8|  19|  Sunday|\n",
      "|2017| January| 21|   3|Saturday|\n",
      "|2017| January| 23|  21|  Monday|\n",
      "|2017|February|  2|  19|Thursday|\n",
      "|2017|February|  5|  16|  Sunday|\n",
      "|2017|February| 21|  15| Tuesday|\n",
      "|2017|   March|  2|   8|Thursday|\n",
      "|2017|   April|  2|   2|  Sunday|\n",
      "|2017|   April|  6|   8|Thursday|\n",
      "|2017|   April| 30|  10|  Sunday|\n",
      "|2017|     May|  2|   2| Tuesday|\n",
      "|2017|     May| 20|  16|Saturday|\n",
      "|2017|     May| 21|  19|  Sunday|\n",
      "|2017|    June| 27|   0| Tuesday|\n",
      "|2017|    July| 18|   9| Tuesday|\n",
      "|2017|    July| 18|  22| Tuesday|\n",
      "|2017|    July| 20|   0|Thursday|\n",
      "|2017|    July| 21|  19|  Friday|\n",
      "+----+--------+---+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking top 20 rows\n",
    "dim_date.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions  import date_format\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "from pyspark.sql.functions import to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating New Month column with Integer value. \n",
    "dim_date=dim_date.withColumn('month_new', date_format(to_date(col('month'),'MMMMM'),'MM').cast(IntegerType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding new Month, day and hours columns with Zeroes \n",
    "dim_date=dim_date.withColumn('month_new', lpad(col('month_new'),2,'0')).withColumn('day_new', lpad(col('day'),2,'0')).withColumn('hour_new', lpad(col('hour'),2,'0'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column Full_Date_time by combining Year, new month, day, hour and \"00\" value to create timestamp in YYYYMMDDMI24HHMI format.\n",
    "dim_date_final=dim_date.withColumn(\"full_date_time\",concat(col('year'),col('month_new'),col('day_new'),col('hour_new'),lit('00')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating full_date by concating other columns\n",
    "# dim_date_final = dim_date.withColumn(\"full_date\",from_unixtime(unix_timestamp(concat(dim_date.year.cast(StringType()),dim_date.month.cast(StringType()),lpad(dim_date.day.cast(StringType()),2,'0'),lpad(dim_date.hour.cast(StringType()),2,'0')),'yyyyMMMMMddHH'),'YYYY-MM-DD HH:mm:SS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---+----+--------+---------+-------+--------+--------------+\n",
      "|year|   month|day|hour| weekday|month_new|day_new|hour_new|full_date_time|\n",
      "+----+--------+---+----+--------+---------+-------+--------+--------------+\n",
      "|2017| January|  1|   9|  Sunday|       01|     01|      09|  201701010900|\n",
      "|2017| January|  3|   5| Tuesday|       01|     03|      05|  201701030500|\n",
      "|2017| January|  8|  19|  Sunday|       01|     08|      19|  201701081900|\n",
      "|2017| January| 21|   3|Saturday|       01|     21|      03|  201701210300|\n",
      "|2017| January| 23|  21|  Monday|       01|     23|      21|  201701232100|\n",
      "|2017|February|  2|  19|Thursday|       02|     02|      19|  201702021900|\n",
      "|2017|February|  5|  16|  Sunday|       02|     05|      16|  201702051600|\n",
      "|2017|February| 21|  15| Tuesday|       02|     21|      15|  201702211500|\n",
      "|2017|   March|  2|   8|Thursday|       03|     02|      08|  201703020800|\n",
      "|2017|   April|  2|   2|  Sunday|       04|     02|      02|  201704020200|\n",
      "+----+--------+---+----+--------+---------+-------+--------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking newly created columns\n",
    "dim_date_final.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8685"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the count for validation hence verified \n",
    "\n",
    "dim_date_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating primary key for the dimension with name date_id\n",
    "dim_date_final= dim_date_final.withColumn(\"new_column\",lit(\"ABC\"))\n",
    "w = Window().partitionBy('new_column').orderBy(lit('A'))\n",
    "dim_date_final= dim_date_final.withColumn(\"date_id\", row_number().over(w)).drop(\"new_column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---+----+--------+---------+-------+--------+--------------+-------+\n",
      "|year|   month|day|hour| weekday|month_new|day_new|hour_new|full_date_time|date_id|\n",
      "+----+--------+---+----+--------+---------+-------+--------+--------------+-------+\n",
      "|2017| January|  1|   9|  Sunday|       01|     01|      09|  201701010900|      1|\n",
      "|2017| January|  3|   5| Tuesday|       01|     03|      05|  201701030500|      2|\n",
      "|2017| January|  8|  19|  Sunday|       01|     08|      19|  201701081900|      3|\n",
      "|2017| January| 21|   3|Saturday|       01|     21|      03|  201701210300|      4|\n",
      "|2017| January| 23|  21|  Monday|       01|     23|      21|  201701232100|      5|\n",
      "|2017|February|  2|  19|Thursday|       02|     02|      19|  201702021900|      6|\n",
      "|2017|February|  5|  16|  Sunday|       02|     05|      16|  201702051600|      7|\n",
      "|2017|February| 21|  15| Tuesday|       02|     21|      15|  201702211500|      8|\n",
      "|2017|   March|  2|   8|Thursday|       03|     02|      08|  201703020800|      9|\n",
      "|2017|   April|  2|   2|  Sunday|       04|     02|      02|  201704020200|     10|\n",
      "|2017|   April|  6|   8|Thursday|       04|     06|      08|  201704060800|     11|\n",
      "|2017|   April| 30|  10|  Sunday|       04|     30|      10|  201704301000|     12|\n",
      "|2017|     May|  2|   2| Tuesday|       05|     02|      02|  201705020200|     13|\n",
      "|2017|     May| 20|  16|Saturday|       05|     20|      16|  201705201600|     14|\n",
      "|2017|     May| 21|  19|  Sunday|       05|     21|      19|  201705211900|     15|\n",
      "|2017|    June| 27|   0| Tuesday|       06|     27|      00|  201706270000|     16|\n",
      "|2017|    July| 18|   9| Tuesday|       07|     18|      09|  201707180900|     17|\n",
      "|2017|    July| 18|  22| Tuesday|       07|     18|      22|  201707182200|     18|\n",
      "|2017|    July| 20|   0|Thursday|       07|     20|      00|  201707200000|     19|\n",
      "|2017|    July| 21|  19|  Friday|       07|     21|      19|  201707211900|     20|\n",
      "+----+--------+---+----+--------+---------+-------+--------+--------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking newly created column\n",
    "dim_date_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data from dim_date_final\n",
    "date = dim_date_final.select(\"date_id\",\"full_date_time\",\"year\",\"month\",\"day\",\"hour\",\"weekday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8685"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the count for validation\n",
    "date.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Atm dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new data fame with atm related columns\n",
    "dim_atm = input_df.select([input_df.atm_id.alias(\"atm_number\"),input_df.atm_manufacturer.alias(\"atm_manufacturer\"),input_df.atm_lat.alias(\"lat\"),input_df.atm_lon.alias(\"lon\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+------+------+\n",
      "|atm_number|atm_manufacturer|   lat|   lon|\n",
      "+----------+----------------+------+------+\n",
      "|         1|             NCR|55.233|11.763|\n",
      "|         2|             NCR|57.043|  9.95|\n",
      "|         2|             NCR|57.043|  9.95|\n",
      "+----------+----------------+------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking top 3 rows\n",
    "dim_atm.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking count\n",
    "dim_atm.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To add atm_location_id of dim_location df as a foreign key to the atm table, adding left join to the atm table and locatino table.\n",
    "dim_atm = dim_atm.join(location, on = [\"lat\",\"lon\"],how = \"leftouter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking distinct values to avoid repeated values \n",
    "atm_distinct =dim_atm.distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----------+----------------+---------------+--------------+----------------+-------------+-------+\n",
      "|   lat|   lon|atm_number|atm_manufacturer|atm_location_id|      location|      streetname|street_number|zipcode|\n",
      "+------+------+----------+----------------+---------------+--------------+----------------+-------------+-------+\n",
      "|56.448| 9.401|        18| Diebold Nixdorf|             13|        Viborg|       Toldboden|            3|   8800|\n",
      "|55.705| 9.532|       101|             NCR|              6|Bryggen  Vejle|SÃƒÂ¸nderbrogade|            2|   7100|\n",
      "|56.716|10.114|         9| Diebold Nixdorf|             25|       Hadsund|       Storegade|           12|   9560|\n",
      "|55.859| 9.854|        64|             NCR|             88|       Horsens| GrÃƒÂ¸nlandsvej|            5|   8700|\n",
      "+------+------+----------+----------------+---------------+--------------+----------------+-------------+-------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking dataframe \n",
    "atm_distinct.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking count for validation hence verified\n",
    "atm_distinct.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding our primary key to the 156 sets of data\n",
    "atm_distinct= atm_distinct.withColumn(\"new_column\",lit(\"ABC\"))\n",
    "w = Window().partitionBy('new_column').orderBy(lit('A'))\n",
    "atm_distinct= atm_distinct.withColumn(\"atm_id\", row_number().over(w)).drop(\"new_column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+----------+----------------+---------------+--------------+----------------+-------------+-------+------+\n",
      "|   lat|  lon|atm_number|atm_manufacturer|atm_location_id|      location|      streetname|street_number|zipcode|atm_id|\n",
      "+------+-----+----------+----------------+---------------+--------------+----------------+-------------+-------+------+\n",
      "|56.448|9.401|        18| Diebold Nixdorf|             13|        Viborg|       Toldboden|            3|   8800|     1|\n",
      "|55.705|9.532|       101|             NCR|              6|Bryggen  Vejle|SÃƒÂ¸nderbrogade|            2|   7100|     2|\n",
      "+------+-----+----------+----------------+---------------+--------------+----------------+-------------+-------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking newly created primary key \n",
    "atm_distinct.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating atm from atm_distinct\n",
    "atm = atm_distinct.select('atm_id','atm_number','atm_manufacturer','atm_location_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------------+---------------+\n",
      "|atm_id|atm_number|atm_manufacturer|atm_location_id|\n",
      "+------+----------+----------------+---------------+\n",
      "|     1|        18| Diebold Nixdorf|             13|\n",
      "|     2|       101|             NCR|              6|\n",
      "|     3|         9| Diebold Nixdorf|             25|\n",
      "+------+----------+----------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking top rows of atm\n",
    "atm.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rechecking the count for validation\n",
    "\n",
    "atm.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Creating fact table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating alias \n",
    "input_df = input_df.alias('input_df')\n",
    "date = date.alias('date')\n",
    "dim_card_type = dim_card_type.alias('dim_card_type')\n",
    "dim_location = dim_location.alias('dim_location')\n",
    "atm = atm.alias('atm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Creating fact table will take 4 steps by outer left joining the input table with dimension tables\n",
    "#### - Dropping columns as required except primary keys of dimension table as they will act as foreign key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating firts_df by left join of date dimension on input data frame and dropping columns \n",
    "first_df =input_df.join(date, on = ['year','month','day','hour','weekday'],how='left').select('input_df.*','date.date_id').drop(*['year','month','day','hour','weekday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Creating alias for first\n",
    "first_df = first_df.alias(\"first_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking count for first step for validation \n",
    "first_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating second_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating second_df by joining card_type dimension with first_df\n",
    "second_df = first_df.join(dim_card_type, on = ['card_type'], how = 'left').select('first_df.*','dim_card_type.card_type_id').drop(*['card_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking count for validation at each step\n",
    "second_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- atm_id: string (nullable = true)\n",
      " |-- atm_manufacturer: string (nullable = true)\n",
      " |-- atm_location: string (nullable = true)\n",
      " |-- atm_streetname: string (nullable = true)\n",
      " |-- atm_street_number: integer (nullable = true)\n",
      " |-- atm_zipcode: integer (nullable = true)\n",
      " |-- atm_lat: float (nullable = true)\n",
      " |-- atm_lon: float (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- weather_lat: float (nullable = true)\n",
      " |-- weather_lon: float (nullable = true)\n",
      " |-- weather_city_id: integer (nullable = true)\n",
      " |-- weather_city_name: string (nullable = true)\n",
      " |-- temp: float (nullable = true)\n",
      " |-- pressure: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_deg: integer (nullable = true)\n",
      " |-- rain_3h: float (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      " |-- date_id: integer (nullable = true)\n",
      " |-- card_type_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking schema\n",
    "second_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Creating alias\n",
    "second_df = second_df.alias('second_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating third_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating third_df by joining location dimension with second_df by performing outer join\n",
    "third_df = second_df.withColumnRenamed('atm_location','location').withColumnRenamed('atm_lat','lat').withColumnRenamed('atm_lon','lon').withColumnRenamed('atm_streetname','streetname').withColumnRenamed('atm_street_number','street_number').withColumnRenamed('atm_zipcode','zipcode').join(dim_location, on = ['location','lat','lon','streetname','street_number','zipcode'],how = 'left').select('second_df.*','dim_location.atm_location_id').drop(*['location','lat','lon','streetname','street_number','zipcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking count again\n",
    "third_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating alias\n",
    "third_df= third_df.alias('third_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----------------+--------+------------------+----------+------------+------------+-----------+-----------+---------------+-----------------+------+--------+--------+----------+--------+-------+----------+----------+------------+-------------------+-------+------------+---------------+\n",
      "|atm_status|atm_id|atm_manufacturer|currency|transaction_amount|   service|message_code|message_text|weather_lat|weather_lon|weather_city_id|weather_city_name|  temp|pressure|humidity|wind_speed|wind_deg|rain_3h|clouds_all|weather_id|weather_main|weather_description|date_id|card_type_id|atm_location_id|\n",
      "+----------+------+----------------+--------+------------------+----------+------------+------------+-----------+-----------+---------------+-----------------+------+--------+--------+----------+--------+-------+----------+----------+------------+-------------------+-------+------------+---------------+\n",
      "|    Active|     6|             NCR|     DKK|              5622|Withdrawal|        null|        null|     55.566|      9.753|        2621951|       Fredericia|283.75|     998|      93|        10|     220|    0.0|        75|       803|      Clouds|      broken clouds|    460|           1|             63|\n",
      "|    Active|     6|             NCR|     DKK|              2032|Withdrawal|        null|        null|     55.566|      9.753|        2621951|       Fredericia|288.16|    1013|      87|         1|     220|    0.0|        40|       802|      Clouds|   scattered clouds|    628|           1|             63|\n",
      "+----------+------+----------------+--------+------------------+----------+------------+------------+-----------+-----------+---------------+-----------------+------+--------+--------+----------+--------+-------+----------+----------+------------+-------------------+-------+------------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating alias \n",
    "third_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- atm_id: string (nullable = true)\n",
      " |-- atm_manufacturer: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- weather_lat: float (nullable = true)\n",
      " |-- weather_lon: float (nullable = true)\n",
      " |-- weather_city_id: integer (nullable = true)\n",
      " |-- weather_city_name: string (nullable = true)\n",
      " |-- temp: float (nullable = true)\n",
      " |-- pressure: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_deg: integer (nullable = true)\n",
      " |-- rain_3h: float (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      " |-- date_id: integer (nullable = true)\n",
      " |-- card_type_id: integer (nullable = true)\n",
      " |-- atm_location_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking schema\n",
    "third_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming atm_id as atm_number as atm_id imported from input df\n",
    "third_df = third_df.withColumnRenamed('atm_id',\"atm_number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- atm_number: string (nullable = true)\n",
      " |-- atm_manufacturer: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- weather_lat: float (nullable = true)\n",
      " |-- weather_lon: float (nullable = true)\n",
      " |-- weather_city_id: integer (nullable = true)\n",
      " |-- weather_city_name: string (nullable = true)\n",
      " |-- temp: float (nullable = true)\n",
      " |-- pressure: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_deg: integer (nullable = true)\n",
      " |-- rain_3h: float (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      " |-- date_id: integer (nullable = true)\n",
      " |-- card_type_id: integer (nullable = true)\n",
      " |-- atm_location_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking schema\n",
    "third_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating fourth data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Craeting fourth_df by left joining of third with atm dimension\n",
    "fourth_df= third_df.join(atm,on =['atm_number','atm_manufacturer','atm_location_id'],how ='left').select('third_df.*','atm.atm_id').drop(*['atm_manufacturer','atm_nummber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking count for validation hence verifed \n",
    "fourth_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- atm_location_id: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- weather_lat: float (nullable = true)\n",
      " |-- weather_lon: float (nullable = true)\n",
      " |-- weather_city_id: integer (nullable = true)\n",
      " |-- weather_city_name: string (nullable = true)\n",
      " |-- temp: float (nullable = true)\n",
      " |-- pressure: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_deg: integer (nullable = true)\n",
      " |-- rain_3h: float (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      " |-- date_id: integer (nullable = true)\n",
      " |-- card_type_id: integer (nullable = true)\n",
      " |-- atm_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking schema\n",
    "fourth_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+--------+------------------+----------+------------+------------+-----------+-----------+---------------+-----------------+------+--------+--------+----------+--------+-------+----------+----------+------------+-------------------+-------+------------+------+\n",
      "|atm_location_id|atm_status|currency|transaction_amount|   service|message_code|message_text|weather_lat|weather_lon|weather_city_id|weather_city_name|  temp|pressure|humidity|wind_speed|wind_deg|rain_3h|clouds_all|weather_id|weather_main|weather_description|date_id|card_type_id|atm_id|\n",
      "+---------------+----------+--------+------------------+----------+------------+------------+-----------+-----------+---------------+-----------------+------+--------+--------+----------+--------+-------+----------+----------+------------+-------------------+-------+------------+------+\n",
      "|             57|  Inactive|     DKK|              1764|Withdrawal|        null|        null|     57.165|     10.146|        2620275|        Hjallerup|293.15|    1004|      72|         5|     220|    0.0|        40|       802|      Clouds|   scattered clouds|   2559|           1|    28|\n",
      "|             57|  Inactive|     DKK|              9159|Withdrawal|        null|        null|     57.165|     10.146|        2620275|        Hjallerup|281.15|     993|      93|        11|     210|    0.0|        90|       804|      Clouds|    overcast clouds|   6428|           1|    28|\n",
      "|             57|  Inactive|     DKK|              7786|Withdrawal|        null|        null|     57.165|     10.146|        2620275|        Hjallerup|290.15|    1023|      59|         3|     270|    0.0|        40|       802|      Clouds|   scattered clouds|   5233|           1|    28|\n",
      "+---------------+----------+--------+------------------+----------+------------+------------+-----------+-----------+---------------+-----------------+------+--------+--------+----------+--------+-------+----------+----------+------------+-------------------+-------+------------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# top 3 rows \n",
    "fourth_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rechecking count\n",
    "fourth_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final step creating fact table fact_atm_trans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating fact table from fourth_df\n",
    "fact_atm_trans = fourth_df.alias(\"fact_atm_trans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking count and hence verified \n",
    "fact_atm_trans.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding our primary key to fact table\n",
    "fact_atm_trans= fact_atm_trans.withColumn(\"new_column\",lit(\"ABC\"))\n",
    "w = Window().partitionBy('new_column').orderBy(lit('A'))\n",
    "fact_atm_trans= fact_atm_trans.withColumn(\"trans_id\", row_number().over(w)).drop(\"new_column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- atm_location_id: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- weather_lat: float (nullable = true)\n",
      " |-- weather_lon: float (nullable = true)\n",
      " |-- weather_city_id: integer (nullable = true)\n",
      " |-- weather_city_name: string (nullable = true)\n",
      " |-- temp: float (nullable = true)\n",
      " |-- pressure: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_deg: integer (nullable = true)\n",
      " |-- rain_3h: float (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      " |-- date_id: integer (nullable = true)\n",
      " |-- card_type_id: integer (nullable = true)\n",
      " |-- atm_id: integer (nullable = true)\n",
      " |-- trans_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking schema of fact table\n",
    "fact_atm_trans.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    " # dropping irrelevant columns as per schema \n",
    "fact_atm_trans = fact_atm_trans.drop('weather_lat','weather_lon','weather_city_id','weather_city_name','temp','pressure','humidity','wind_speed','wind_deg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming atm_location_id as weather_loaction_id as per schema \n",
    "fact_atm_trans = fact_atm_trans.withColumnRenamed(\"atm_location_id\",\"weather_loc_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- weather_loc_id: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- rain_3h: float (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      " |-- date_id: integer (nullable = true)\n",
      " |-- card_type_id: integer (nullable = true)\n",
      " |-- atm_id: integer (nullable = true)\n",
      " |-- trans_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking final schema\n",
    "fact_atm_trans.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_atm_trans1 = fact_atm_trans.select('trans_id','atm_id','weather_loc_id','date_id','card_type_id','atm_status','currency','service','transaction_amount','message_code','message_text','rain_3h','clouds_all','weather_id','weather_main','weather_description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_atm_trans1 = fact_atm_trans1.alias('fact_atm_trans1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------+-------+------------+----------+--------+----------+------------------+------------+------------+-------+----------+----------+------------+--------------------+\n",
      "|trans_id|atm_id|weather_loc_id|date_id|card_type_id|atm_status|currency|   service|transaction_amount|message_code|message_text|rain_3h|clouds_all|weather_id|weather_main| weather_description|\n",
      "+--------+------+--------------+-------+------------+----------+--------+----------+------------------+------------+------------+-------+----------+----------+------------+--------------------+\n",
      "|       1|    28|            57|   2559|           1|  Inactive|     DKK|Withdrawal|              1764|        null|        null|    0.0|        40|       802|      Clouds|    scattered clouds|\n",
      "|       2|     4|            88|   3357|           8|    Active|     DKK|Withdrawal|               845|        null|        null|    0.0|        92|       300|     Drizzle|light intensity d...|\n",
      "+--------+------+--------------+-------+------------+----------+--------+----------+------------------+------------+------------+-------+----------+----------+------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_atm_trans1.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trans_id: integer (nullable = true)\n",
      " |-- atm_id: integer (nullable = true)\n",
      " |-- weather_loc_id: integer (nullable = true)\n",
      " |-- date_id: integer (nullable = true)\n",
      " |-- card_type_id: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- rain_3h: float (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_atm_trans1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the tables to s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving fact table as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_atm_trans1.coalesce(1).write.save(\"s3a://saavnetl/fact-table\",format='csv',header='false')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dim tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.dim-atm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dim-atm/\n",
    "atm.coalesce(1).write.save(\"s3a://saavnetl/dim-atm\",format='csv',header='false'),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 dim-card-type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### dim-card-type/\n",
    "card_type.coalesce(1).write.save(\"s3a://saavnetl/dim-card-type\",format='csv',header='false'),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 dim-date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dim-date\n",
    "date.coalesce(1).write.save(\"s3a://saavnetl/dim-date\",format='csv',header='false'),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 dim-location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dim-location\n",
    "location.coalesce(1).write.save(\"s3a://saavnetl/dim-location\",format='csv',header='false'),"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
